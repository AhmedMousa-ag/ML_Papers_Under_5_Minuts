# DiffusionDet: Diffusion Model for Object Detection

Authors: Shoufa Chen, Peize Sun, Yibing Song, and Ping Luo

Author propse DiffusionDet, a new framwork that formulates object detection as a denoising diffusion process from noisy boxes to object boxes. acheving favorable performance compared to previous well-established detectors.

## Introduction

Authors designed a novel framework that directly detects objects from a set of random boxes. starting from purely random boxes, which do not contain learnable parameters that need to be optimized in training, they expect to gradually refine the positions and sizes of these boxes until they perfectly cover the targeted objects. 

$ Figure 1

## Approach

### Architecture 

$ Figure 3

Since the diffusion model generate data samples iteratively, it needs to run model *f0* multiple times at the inference stage. However it would be computationally intractable to directly apply *f0* on the raw image at every iterative step. Therefore, we propose to separate the whole model into two parts, *image encoder* and *detection decoder*, where the former runs only once to extract a deep feature representation from the raw input image *x*, and the latter takes this deep feature as condition, instead of the raw image, to progressively refine the box predictions from noisy boxes *xt*.

#### Image encoder

Image encoder takes as input the raw image and extracts its high-level features for the following detection decoder. They implement DiffusionDet with both Convolutional Neural Networks such as ResNet and Transformer-based models like Swin. Feature Pyramid Network is used to generate multi-scale feature maps for both ResNet and Swin backbones.

#### Detection decoder

Borrowed from Sparse R-CNN, the detection decoder takes as input a set of proposal boxes to crop RoI-feature from feature map generated by image encoder, and sends these RoI-features to detection head to obtain box regression and classificatioin results. Following detection decoder is composed of 6 cascading stages. The differences between authors decoders and the one in Sparse R-CNN are:

 1-DiffusionDet begins from random boxes while Sparse R-CNN uses a fixed set of learned boxes in inference.

2- Sparse R-CNN takes as input pairs of the propsal boxes and its corresponding proposal feature, while DiffusionDet needs the proposal boxes only.

3- DiffusionDet re-uses the detector head in iterative sampling steps and the parameters are shared across different steps, each of which is specified to the diffusion process by timestep embedding, while Sparse R-CNN uses the detection decoder only once in the forward pass.

### Training

During training, first construct the diffusion process from ground-truth boxes to noisy boxes and then train the model to reverse this process.

Below is a pseudo-code of DiffusionDet training procedure.

```
def train_loss(images, gt_boxes):
    """
    images: [B, H, W, 3] 
    gt_boxes: [B, *, 4]
    # B: batch
    # N: number of proposal boxes
    """

    # Encode image features
    feats = image_encoder(images)

    # Pad gt_boxes to N
    pb = pad_boxes(gt_boxes) # padded boxes: [B, N, 4]

    # Signal scaling
    pb = (pb * 2 - 1) * scale

    # Corrupt gt_boxes
    t = randint(0, T)
    # time step
    eps = normal(mean=0, std=1) # noise: [B, N, 4]
    pb_crpt = sqrt(
    alpha_cumprod(t)) * pb +
    sqrt(1 - alpha_cumprod(t)) * eps

    # Predict
    pb_pred = detection_decoder(pb_crpt, feats, t)

    # Set prediction loss
    loss = set_prediction_loss(pb_pred, gt_boxes)

    return loss
```

#### Ground truth boxes padding

For modern object detection benchmarks the number of instance of interest typically varies across images. Therefore they first *pad* some extra boxes to original ground truth boxes such that all boxes are summed up to a fixed number $Ntrain$. 

#### Box corruption

Adding Gaussion noises to the padded ground truth boxes. The noise scale is controlled by $ α t $ which adopts the monotonically decreasing cosine schedule for $ α t $ in different time step $t  $.

Notably, the ground truth box coordinates need to be scaled as well since the signal-to-noise ratio has a significant effect on the performance of diffusion model. Authors observed that object detection favors a relatively higher signal scaling value than image generation stask.

#### Training losses

The detection detector takes as input $Ntrain$ corrupted boxes and predicts $Ntrain$ predictions of category classification and box coordinates. They apply set prediction loss on the set of $Ntrain$ predictions. Then assigning multiple predctions to each ground truth by selecting the top $k$ predictions with the least cost by an optimal transport assignment method.

### Inference

The inference procedure is a denoising sampling process from noise to object boxes. Starting from boxes sampled in Gaussian distribution, the model progressively refines its predictions, as shown below.

```
def infer(images, steps, T):
    """
    images: [B, H, W, 3]
    # steps: number of sample steps
    # T: number of time steps
    """

    # Encode image features
    feats = image_encoder(images)

    # noisy boxes: [B, N, 4]
    pb_t = normal(mean=0, std=1)

    # uniform sample step size
    times = reversed(linespace(-1, T, steps))

    # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]
    time_pairs = list(zip(times[:-1], times[1:]

    for t_now, t_next in zip(time_pairs):
      # Predict pb_0 from pb_t
      pb_pred = detection_decoder(pb_t, feats, t_now)
      # Predict
      pb_pred = detection_decoder(pb_crpt, feats, t) 
      # Estimate pb_t at t_next
      pb_t = ddim_step(pb_t, pb_pred, t_now, t_next)
      # Set prediction loss
      loss = set_prediction_loss(pb_pred, gt_boxes)
      # Box renewal
      pb_t = box_renewal(pb_t)

    return pb_pred
```

#### Sampling step

In each sampling step, the random boxes or the estimated boxes from the last sampling step are sent into the detection decoder to predict the category classification and box coordinates. After obtaining the boxes of the current step, DDIM is adopted to estimate the boxes without DDIM to the next step is also an optional profressive refinement strategy. However it brings significant deterioration.

#### Box renewal

After each sampling step, the predicted boxes can be coarsely categorized into two types, *desired* and *undiseired* predictions. The desired predictions contain boxes that are properly located at corresponding objects, while the undesired ones ar distirbuted arbitrarily. Directly sending these undesired boxes to the next sampling iteration would not bring a benefit since their distribution is not constructed by box corruption in training.

To make inference better align with training, authors propose the strategy of *box renewal* to revive these undersired boxes by replacing them with random boxes. Specifically, authors first filtered out undesired boxes with scores lower than a particular thershold. Then concatenate the remaining boxes with new random boxes sampled from a Gaussian distribution.

### Benchmarking on Detection Datasets

Authors compared DiffusionDet with previous detectors on MS-COCO and LVIS dataset. We adopt
500 boxes for both training and inference in this subsection.

$ Table 3


DiffusionDet ablation experiments on MS-COCO. Aurhors report AP, AP 50 , and AP 75 . If not specified, the default setting is: the
backbone is ResNet-50 with FPN, the signal scale is 2.0, ground-truth boxes padding method is concatenating Gaussian random
boxes, DDIM and box renewal are used in sampling step, where the score threshold in box renewal is 0.5, both training and evaluation use
300 boxes. Default settings are marked in gray .
